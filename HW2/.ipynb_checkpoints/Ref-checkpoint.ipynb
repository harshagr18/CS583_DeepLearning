{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c-3SQ2WTvnvc"
   },
   "source": [
    "# Home 4: Build a CNN for image recognition.\n",
    "\n",
    "### Name: Tarquin Bennett\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MPJPbTpTvnvg"
   },
   "source": [
    "## 0. You will do the following:\n",
    "\n",
    "1. Read, complete, and run the code.\n",
    "\n",
    "2. **Make substantial improvements** to maximize the accurcy.\n",
    "    \n",
    "3. Convert the .IPYNB file to .HTML file.\n",
    "\n",
    "    * The HTML file must contain the code and the output after execution.\n",
    "    \n",
    "    * Missing **the output after execution** will not be graded.\n",
    "    \n",
    "4. Upload this .HTML file to your Google Drive, Dropbox, or Github repo. (If you submit the file to Google Drive or Dropbox, you must make the file \"open-access\". The delay caused by \"deny of access\" may result in late penalty.)\n",
    "\n",
    "4. Submit the link to this .HTML file to Canvas.\n",
    "\n",
    "    * Example: https://github.com/wangshusen/CS583-2020S/blob/master/homework/HM4/HM4.html\n",
    "\n",
    "\n",
    "## Requirements:\n",
    "\n",
    "1. You can use whatever CNN architecture, including VGG, Inception, and ResNet. However, you must build the networks layer by layer. You must NOT import the archetectures from ```keras.applications```.\n",
    "\n",
    "2. Make sure ```BatchNormalization``` is between a ```Conv```/```Dense``` layer and an ```activation``` layer.\n",
    "\n",
    "3. If you want to regularize a ```Conv```/```Dense``` layer, you should place a ```Dropout``` layer **before** the ```Conv```/```Dense``` layer.\n",
    "\n",
    "4. An accuracy above 70% is considered reasonable. An accuracy above 80% is considered good. Without data augmentation, achieving 80% accuracy is difficult.\n",
    "\n",
    "\n",
    "## Google Colab\n",
    "\n",
    "- If you do not have GPU, the training of a CNN can be slow. Google Colab is a good option.\n",
    "\n",
    "- Keep in mind that you must download it as an IPYNB file and then use IPython Notebook to convert it to HTML.\n",
    "\n",
    "- Also keep in mind that the IPYNB and HTML files must contain the outputs. (Otherwise, the instructor will not be able to know the correctness and performance.) Do the followings to keep the outputs.\n",
    "\n",
    "- In Colab, go to ```Runtime``` --> ```Change runtime type``` --> Do NOT check ```Omit code cell output when saving this notebook```. In this way, the downloaded IPYNB file contains the outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkPyaXryvnvh"
   },
   "source": [
    "## 1. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPeeg7_gvnvh"
   },
   "source": [
    "### 1.1. Load data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xgCIeSxBvnvi",
    "outputId": "8348f8fb-e02e-47b5-f5f2-449d3ea90e5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Enabling eager execution\n",
      "INFO:tensorflow:Enabling v2 tensorshape\n",
      "INFO:tensorflow:Enabling resource variables\n",
      "INFO:tensorflow:Enabling tensor equality\n",
      "INFO:tensorflow:Enabling control flow v2\n",
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 12s 0us/step\n",
      "170508288/170498071 [==============================] - 12s 0us/step\n",
      "shape of x_train: (50000, 32, 32, 3)\n",
      "shape of y_train: (50000, 1)\n",
      "shape of x_test: (10000, 32, 32, 3)\n",
      "shape of y_test: (10000, 1)\n",
      "number of classes: 10\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "import numpy\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "print('shape of x_train: ' + str(x_train.shape))\n",
    "print('shape of y_train: ' + str(y_train.shape))\n",
    "print('shape of x_test: ' + str(x_test.shape))\n",
    "print('shape of y_test: ' + str(y_test.shape))\n",
    "print('number of classes: ' + str(numpy.max(y_train) - numpy.min(y_train) + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O7sMji_Lvnvi"
   },
   "source": [
    "### 1.2. One-hot encode the labels\n",
    "\n",
    "In the input, a label is a scalar in $\\{0, 1, \\cdots , 9\\}$. One-hot encode transform such a scalar to a $10$-dim vector. E.g., a scalar ```y_train[j]=3``` is transformed to the vector ```y_train_vec[j]=[0, 0, 0, 1, 0, 0, 0, 0, 0, 0]```.\n",
    "\n",
    "1. Define a function ```to_one_hot``` that transforms an $n\\times 1$ array to a $n\\times 10$ matrix.\n",
    "\n",
    "2. Apply the function to ```y_train``` and ```y_test```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gY3hi81pvnvi",
    "outputId": "8caca89a-7a96-4514-82ad-98815b5166fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of y_train_vec: (50000, 10)\n",
      "Shape of y_test_vec: (10000, 10)\n",
      "[6]\n",
      "[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "def to_one_hot(y, num_class=10):\n",
    "    y_vec = numpy.zeros((y.shape[0],10))\n",
    "    for i in range(len(y)):\n",
    "        y_vec[i][y[i]] = 1\n",
    "    return y_vec\n",
    "\n",
    "y_train_vec = to_one_hot(y_train)\n",
    "y_test_vec = to_one_hot(y_test)\n",
    "\n",
    "print('Shape of y_train_vec: ' + str(y_train_vec.shape))\n",
    "print('Shape of y_test_vec: ' + str(y_test_vec.shape))\n",
    "\n",
    "print(y_train[0])\n",
    "print(y_train_vec[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I-Qob_e3vnvj"
   },
   "source": [
    "#### Remark: the outputs should be\n",
    "* Shape of y_train_vec: (50000, 10)\n",
    "* Shape of y_test_vec: (10000, 10)\n",
    "* [6]\n",
    "* [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OPKCjsXqvnvj"
   },
   "source": [
    "### 1.3. Randomly partition the training set to training and validation sets\n",
    "\n",
    "Randomly partition the 50K training samples to 2 sets:\n",
    "* a training set containing 40K samples\n",
    "* a validation set containing 10K samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVYvYWAIvnvj",
    "outputId": "67de85ea-0e0b-4f75-9c5c-99bf08d90f43"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of x_tr: (40000, 32, 32, 3)\n",
      "Shape of y_tr: (40000, 10)\n",
      "Shape of x_val: (10000, 32, 32, 3)\n",
      "Shape of y_val: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "rand_indices = numpy.random.permutation(50000)\n",
    "train_indices = rand_indices[0:40000]\n",
    "valid_indices = rand_indices[40000:50000]\n",
    "\n",
    "x_val = x_train[valid_indices, :]\n",
    "y_val = y_train_vec[valid_indices, :]\n",
    "\n",
    "x_tr = x_train[train_indices, :]\n",
    "y_tr = y_train_vec[train_indices, :]\n",
    "\n",
    "print('Shape of x_tr: ' + str(x_tr.shape))\n",
    "print('Shape of y_tr: ' + str(y_tr.shape))\n",
    "print('Shape of x_val: ' + str(x_val.shape))\n",
    "print('Shape of y_val: ' + str(y_val.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRyN--Pavnvk"
   },
   "source": [
    "## 2. Build a CNN and tune its hyper-parameters\n",
    "\n",
    "1. Build a convolutional neural network model\n",
    "2. Use the validation data to tune the hyper-parameters (e.g., network structure, and optimization algorithm)\n",
    "    * Do NOT use test data for hyper-parameter tuning!!!\n",
    "3. Try to achieve a validation accuracy as high as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e05Nvf-vnvk"
   },
   "source": [
    "### Remark: \n",
    "\n",
    "The following CNN is just an example. You are supposed to make **substantial improvements** such as:\n",
    "* Add more layers.\n",
    "* Use regularizations, e.g., dropout.\n",
    "* Use batch normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vO9vOxlyvnvk",
    "outputId": "af66b11b-ea84-47f5-a348-be7c1c4e04fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5130      \n",
      "_________________________________________________________________\n",
      "activation_15 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,345,066\n",
      "Trainable params: 1,343,146\n",
      "Non-trainable params: 1,920\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation, BatchNormalization\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(128, (3, 3), padding='same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(512))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eSHRz7vUvnvk"
   },
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_datagen.fit(x_tr)\n",
    "train_generator = train_datagen.flow(x_tr, y_tr, batch_size=64)\n",
    "test_generator = ImageDataGenerator().flow(x_val, y_val, batch_size=64)\n",
    "\n",
    "learning_rate = 0.001 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e6fyIqLMvnvk",
    "outputId": "12b39043-16b3-4699-8352-a41f76d37597"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "625/625 [==============================] - 58s 39ms/step - loss: 1.7236 - acc: 0.3924 - val_loss: 1.1458 - val_acc: 0.5903\n",
      "Epoch 2/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 1.1135 - acc: 0.6068 - val_loss: 1.1064 - val_acc: 0.6518\n",
      "Epoch 3/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.9299 - acc: 0.6753 - val_loss: 2.2095 - val_acc: 0.5255\n",
      "Epoch 4/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.8303 - acc: 0.7055 - val_loss: 1.0552 - val_acc: 0.6865\n",
      "Epoch 5/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.7624 - acc: 0.7297 - val_loss: 1.1256 - val_acc: 0.6631\n",
      "Epoch 6/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.7119 - acc: 0.7520 - val_loss: 0.8385 - val_acc: 0.7267\n",
      "Epoch 7/50\n",
      "625/625 [==============================] - 23s 38ms/step - loss: 0.6947 - acc: 0.7634 - val_loss: 1.6071 - val_acc: 0.6182\n",
      "Epoch 8/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.6446 - acc: 0.7770 - val_loss: 0.7144 - val_acc: 0.7650\n",
      "Epoch 9/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.6324 - acc: 0.7844 - val_loss: 0.6207 - val_acc: 0.7957\n",
      "Epoch 10/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.5934 - acc: 0.7965 - val_loss: 0.6584 - val_acc: 0.7918\n",
      "Epoch 11/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.5863 - acc: 0.8021 - val_loss: 0.8155 - val_acc: 0.7544\n",
      "Epoch 12/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.5637 - acc: 0.8088 - val_loss: 0.7785 - val_acc: 0.7662\n",
      "Epoch 13/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.5484 - acc: 0.8140 - val_loss: 0.7278 - val_acc: 0.7762\n",
      "Epoch 14/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.5352 - acc: 0.8187 - val_loss: 0.5487 - val_acc: 0.8174\n",
      "Epoch 15/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.5229 - acc: 0.8236 - val_loss: 0.7403 - val_acc: 0.7917\n",
      "Epoch 16/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.5115 - acc: 0.8280 - val_loss: 0.7024 - val_acc: 0.7817\n",
      "Epoch 17/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.4994 - acc: 0.8299 - val_loss: 0.6005 - val_acc: 0.8256\n",
      "Epoch 18/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.4845 - acc: 0.8366 - val_loss: 0.6356 - val_acc: 0.8076\n",
      "Epoch 19/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.4847 - acc: 0.8361 - val_loss: 0.8678 - val_acc: 0.7785\n",
      "Epoch 20/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4654 - acc: 0.8432 - val_loss: 0.5893 - val_acc: 0.8277\n",
      "Epoch 21/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4615 - acc: 0.8439 - val_loss: 0.5368 - val_acc: 0.8296\n",
      "Epoch 22/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4520 - acc: 0.8478 - val_loss: 0.6137 - val_acc: 0.8071\n",
      "Epoch 23/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4404 - acc: 0.8529 - val_loss: 0.7503 - val_acc: 0.7998\n",
      "Epoch 24/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4389 - acc: 0.8507 - val_loss: 0.6755 - val_acc: 0.8124\n",
      "Epoch 25/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.4453 - acc: 0.8523 - val_loss: 0.5133 - val_acc: 0.8331\n",
      "Epoch 26/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4182 - acc: 0.8612 - val_loss: 0.7352 - val_acc: 0.8024\n",
      "Epoch 27/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4265 - acc: 0.8551 - val_loss: 0.7326 - val_acc: 0.8085\n",
      "Epoch 28/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4154 - acc: 0.8599 - val_loss: 0.5517 - val_acc: 0.8480\n",
      "Epoch 29/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4096 - acc: 0.8629 - val_loss: 0.4831 - val_acc: 0.8542\n",
      "Epoch 30/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4007 - acc: 0.8647 - val_loss: 0.5445 - val_acc: 0.8317\n",
      "Epoch 31/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3969 - acc: 0.8662 - val_loss: 0.4844 - val_acc: 0.8435\n",
      "Epoch 32/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.4083 - acc: 0.8631 - val_loss: 0.5229 - val_acc: 0.8299\n",
      "Epoch 33/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3864 - acc: 0.8694 - val_loss: 0.5561 - val_acc: 0.8407\n",
      "Epoch 34/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3927 - acc: 0.8661 - val_loss: 0.5159 - val_acc: 0.8601\n",
      "Epoch 35/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3831 - acc: 0.8709 - val_loss: 0.5251 - val_acc: 0.8446\n",
      "Epoch 36/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3714 - acc: 0.8717 - val_loss: 0.6253 - val_acc: 0.8223\n",
      "Epoch 37/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3801 - acc: 0.8734 - val_loss: 0.6055 - val_acc: 0.8254\n",
      "Epoch 38/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3768 - acc: 0.8716 - val_loss: 0.6194 - val_acc: 0.8344\n",
      "Epoch 39/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3637 - acc: 0.8796 - val_loss: 0.4718 - val_acc: 0.8640\n",
      "Epoch 40/50\n",
      "625/625 [==============================] - 23s 37ms/step - loss: 0.3635 - acc: 0.8775 - val_loss: 0.5490 - val_acc: 0.8485\n",
      "Epoch 41/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3609 - acc: 0.8780 - val_loss: 0.4440 - val_acc: 0.8644\n",
      "Epoch 42/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3602 - acc: 0.8755 - val_loss: 0.5546 - val_acc: 0.8454\n",
      "Epoch 43/50\n",
      "625/625 [==============================] - 24s 38ms/step - loss: 0.3543 - acc: 0.8800 - val_loss: 0.4603 - val_acc: 0.8552\n",
      "Epoch 44/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.3428 - acc: 0.8838 - val_loss: 0.5295 - val_acc: 0.8494\n",
      "Epoch 45/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.3441 - acc: 0.8842 - val_loss: 0.4990 - val_acc: 0.8563\n",
      "Epoch 46/50\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.3519 - acc: 0.8804 - val_loss: 0.4693 - val_acc: 0.8567\n",
      "Epoch 47/50\n",
      "625/625 [==============================] - 25s 39ms/step - loss: 0.3425 - acc: 0.8843 - val_loss: 0.5416 - val_acc: 0.8579\n",
      "Epoch 48/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.3362 - acc: 0.8866 - val_loss: 0.4743 - val_acc: 0.8456\n",
      "Epoch 49/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.3327 - acc: 0.8868 - val_loss: 0.5578 - val_acc: 0.8428\n",
      "Epoch 50/50\n",
      "625/625 [==============================] - 24s 39ms/step - loss: 0.3292 - acc: 0.8884 - val_loss: 0.3991 - val_acc: 0.8737\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=, validation_data=test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "XX5ic_Mdvnvl",
    "outputId": "08cfb4e1-ea6d-4bea-c44c-1c2daa592382"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEICAYAAABF82P+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXiU5dX48e9JWMImsolAgKCCiC8SIKKCC26ISkHABUotqAWluFGrYrFq8aWt1V+1WrFF646CWxGLliLi3lcTFJBFNCBgANk3CUuW8/vjfiaZJLNnJpPlfK5rrpm5n+1+Ij5n7l1UFWOMMaa8lGRnwBhjTPVkAcIYY0xAFiCMMcYEZAHCGGNMQBYgjDHGBGQBwhhjTEAJDRAiMlhE1ohIrohMCbC9s4gsEpHlIvK+iKT7bRsrIt96r7GJzKcxxpiKJFHjIEQkFfgGuBDIA7KB0aq6ym+fV4F/qepzInIecI2qXi0iLYEcIAtQYAnQV1V3B7te69atNSMjIyH3YowxtdWSJUt2qGqbQNvqJfC6/YBcVV0HICKzgWHAKr99egC/8j4vBuZ6ny8CFqrqLu/YhcBg4OVgF8vIyCAnJyeuN2CMMbWdiGwIti2RVUwdgO/9vud5af6WASO8z8OBZiLSKsJjjTHGJFCyG6l/DZwjIl8C5wCbgKJIDxaRCSKSIyI527dvT1QejTGmTkpkgNgEdPT7nu6llVDVzao6QlV7A1O9tD2RHOvtO1NVs1Q1q02bgFVoxhhjYpTIAJENdBWRLiLSABgFzPPfQURai4gvD3cBT3ufFwCDRKSFiLQABnlpxhhjqkjCAoSqFgI34h7sq4FXVHWliEwTkaHebgOBNSLyDdAWmO4duwu4HxdksoFpvgZrY4wxVSNh3VyrWlZWllovJmNMXTJrFkydChs3QqdOMH06jBkT3TlEZImqZgXaluxGamOMqVNmzYKMDEhJce+zZoXfFih91iyYMAE2bABV9z5hQtnzVZqq1opX37591RhjEuXFF1U7d1YVce8vvhh9+osvqjZurOoe6e7VuHHobRMnBk5v1apsmu/VuXN09wXkaJDnqlUxGWOMn0DVNuB+nefnl+7XuDGMHQvPPRd5eqNGsHNnxWt27uzeNwQYspaaCkURd/4HESgujmZ/q2IyxtQC0VTBxJoeqNrmllvKPuzBfZ85M7r0QMEBXDDauDHwtmiCA7igFjfBihY17WVVTMbUbtFWwUSb7qsSClRtk+hX587Br52aGji9Vavg9xENQlQxJf3BHq+XBQhjqqd41N2rRv8AjTbdd81oHuzRXiPUQz3aAOg7JtDfKhoWIIwxSRGvX/0vvhj9wzval+8hG82DPZb7CPVQjzZoqqpqTo7qunUx/zeyAGGMSbhAD7F4/eqPpQomlmuE62UUj5JQ3J12mmqPHqrFxTEdbgHCGBOVaH/lBnuwxvPXfVW0QYS792onJ8fdwF/+EvMpLEAYU0ckq69+sD758fx1H6/7C5Ve41x7rfsPsHt3zKewAGFMHRCvX9ihBmDF0ssnnr/ujZ9du1TT0lQnTKjUaSxAGFMDRVvNE686+lDVPNE2FPvnLS6/7ouLVZ99VvW77yL/Q770kupvfxtzHX219ec/uz/yl19W6jShAoSNpDamGvIN2Co/EnfmTPc50LbyA7PiLdRo31at4ODBwPmNdvK4kD74AAYOhBNOgM8+g5YtQ++/eDFceKEbbfb883D11XHMTBIVF0P37tCmDXzySaVOFWokddJ/+cfrZSUIU91F84s5WGmgKnrzhOurf3SjQ3o/U7U7qypsS3i9/ogRqkcdpdqgger556seORJ83+++czfTvbvqGWeoNm+umpeXgEwlwX/+4/7DxOGPjFUxGZNc0bYPxFrNUxV99b8a+htV0O/orH3St1Zd+8B336mmpKhOmaL6zDMuw5MmBd73wAHVzEwXFNasUf3mG9VGjVQvvrjqq5oOHFBdu1b1k09UX39d9a9/Vb37btV77lHdty+2c152mWqbNqqHDlU6e0kLEMBgYA2QC0wJsL0TsBj4ElgOXOKlZwAHgaXe62/hrmUBwlQXyRoPEPf6/kByclzmLrjANZCeeabq4cNx/xsG9Otfu2tv3Oi+33abu/Ennii7X3Gx6ujR7qbmzy9Nf/RRt/9TT4W+TnGx6sqVkT98v/lG9ac/dWMRjjtOtX171ZYtXbQN9h8yJcXl74wzou+BtGGDO/6uu6I7LoikBAggFVgLHAc0AJYBPcrtMxOY6H3uAazX0gCxIprrWYAwiZDM8QDBft3Peq5Ar2nwos7nYv0flpfZllCHD6v27OkegLt2qb78ssvYtdcm/lf5jz+qHn206pVXlqYVFroSQb16qosXl6b/6U8uX7//fdlzFBWpDhyo2qyZe8gGsmeP6siR7vh27VT/8Ad3r4Fs2eKKYfXqqTZpojp8uOrPfqb6i1+o3nijC2h33636xz+6hvV//1t16VLVH35weX/9ddX69VX79FHdvj3yv8XUqe4f3fr1kR8TQrICxBnAAr/vdwF3ldvn78Cdfvt/qhYgTDWRzPEAgUoDLz172P36Pf74kh0/5Ezt3Km4aqp57r3XXfett0rTpk51aQ8/nNhrP/GEu87HH5dN37NH9aST3C/2tWvdQzglRfWKKwIHrXXrVJs2dSWg8tuXLlU94QT3H+XOO1UHDXLXbNJE9eabS6ez2LvX9Ypq3NgFh0mT3EM/FvPnu5LYySe7gBPO4cOqxxyj+pOfxHa9AJIVIC4HnvL7fjXw13L7tAO+AvKA3UBfLQ0QB7yqpw+As8JdzwKEqYx4NRRHWyKIqN9/fr6rt+7Y0e3Qt6/qP/+p+re/ue+vvJL4P9CXX7qH4c9+Vja9qMjVh6ekuIdzIhQXuyDQt2/gh/6336q2aKF64omulNGzpytxBOP7u82YUZr2j3+4B3W7dqoffliavmyZ6s9/7n7pp6SoDhmi2rq1O/6qq9y1K2vRIheEunYtrT4Lxldqe+edyl/XU50DxK+A27zPZwCrcGtUNARaeel9ge+BowJcYwKQA+R06tQpbn8wU7dEWy1UVeMBVFX1q69Ujz3WnWTAAPdg8D0kCwtVTzlFNSND9eDBxP2BjhxxDb5t26ru3Flx+/79Lh/Nm6uuXh3/6y9Y4O7/+eeD77Nokfvl37Jl+InriotVL7zQPZRXrFC95hp3/vPOC14SyMtzpYo2bVzvqezs2O8nkI8/dr2zMjJcSSiYs85y7RxFRXG7dHWuYloJdPT7vg44JsC53geyQl3PShDGXzSNr9E2IIcqQcRrjv4SN9zgTrB4ceBfz4sWuYv84Q8xXiAC99/vrvHGG8H3Wb/ePTy7dg1eZx+rSy5xwSlco/H777uAGomNG90DuV49d2933+0CbjJlZ7sA16GD6kMPuaCRn1+6fflyl9cHH4zrZZMVIOp5D/wufo3UJ5fb5x1gnPf5JGAzIEAbINVLPw7YBLQMdT0LEMYn2hk5o+02Gsl8RXEZD1BY6B6Ml18eer9hw1y9erg67Jdfdq9ofPWVq1656qrw+378ceT7RmrNGvfHvffe+J3T56WXXHvO22/H/9yxWr7cVaf5/lHVq+eq1iZNUh082FWD7dgR10smJUC463IJ8I3Xm2mqlzYNGOp97gF84gWPpcAgL32kV7pYCnwB/CTctSxAGJ9of92Hmnsolrn74+bDD11Gwj3Uv/nGPZivuy7w9uJi1WnTSm/sH/+I7PoFBapZWa5ksG1bZMfcd5+7hn89fmXcdJO7t0gacGuTrVtV581zXVnPPddVh0Hw/8aVkLQAUZUvCxC1V7R199G2D8S9WihebrlFtWHDyAZT/epX7sa/+KJselGR64EDqldf7X6FpqSozpkT+nz797uSCYTf19+BA64xvU+fyteT79njSkZXX12589QGhYWqq1a5v2+cWYAwNVYsyzBG28PIt9ZAtZr+ubjYPWiHDo1s/927XaQ755zStoojR1THjHE3OXmye2AfOOAaOuvVKzuIzN/337tG6ZQUN7gsWi+9pFGVVIJ5+GF3npycyp3HhGQBwtQI8RiBHGpVsFBVSdXOZ5+5zD33XOTHzJjhjnn9dRcILrnEff/978s2cO/Z437hp6W5hl1/n3/uuno2axZ7V8riYtX+/V1//b17YztHYaHrrdO/f2zHm4hZgDDVXrxGIIuUni+ahXDiqrjYjVtYsyb2c9xxh/uVH02PoIICN+CqSxfXJVZE9e9/D7zv9u2uMbRZMxcUVN14irQ019Uy0t5AwXz+ufsD33FH9Mfu3Oka5qFqxnjUcRYgTLWS6LmKor123M2Z4zITafVQecXFrnfNRRdFf6xvzECDBqqvvhp637w8F0xatlS99VZ3XP/+roE0HsaOdfnIzY38mP/8x03lUb++m6Kitq3hUA1ZgDDVRiwlhZhHIBcXu943H3+s+vTTbhbQESPcoK4HHkjMDe7Z4wa2paa6OvxY5stZutTd0MyZseXh8ccj70W0dq2rUgI3SjqeA+42b3aNzJddFn7f/HzXKA+uZFO+sd0kjAUIU23E2qYQ9QjkAwfKzFmk4H6Vdu/uXvXrx2eahPJuvNEFhjfeiH3Gzd/+1h0badfSysrNdV1pE/Fr/fe/d3/7RYuC77N0qasaA9et1X9wmEk4CxAmKWIZlDaNu3UOV6hQVLn2AV9Vy223uYFQubmujl41ul+20fj8c3eDN93kvg8bFtuc/T16uFlHa4ODB101Vs+epX//wkIXFB591M2cWr++K3Ulai4nE5IFCFPlYulJNOv5Qt2Z4naYfvSfKtc+cMcd7sETbNK26dM17C/baBQUqPbu7apr9uxxab5Vv154IfLzrF7tjnnssfjkqzp47TUtqcIaMsRNqOf/H/7666Ob7trElQUIkzDBqnlimqvo009dQseO7uG+ZEnsGcvKcv39g8nPd5k85ZT4zMHzyCNaoddNUZFqt26qp58e+Xn+93/deWrL0piqrurq/PPdfZ14our48S5oxmk9A1M5FiBMQoTqNhqsKinkoLSpU13de26um7DsxBNDT9sczK5d7uTh5u/x9TZ68snor+EvL89VWQ0eXLEe3zfYK9Jg17u3W2WstsnPr7o2FRMVCxCm0kJ1TT2Vz/RrumkG60pqDUKtpRBUZqZbwlLVVf2IuOqHaL3xhrtYuJ48xcVuvEBlBnSpunr0tLTA0zTv3u2iZiRz6Kxd6/L90EOx58WYKFmAMJUSrmvqDG5QBX2S68qUEqIalJaX53byn7b69ttd2ty50WX4xhvdxSJZKzk7213jzjuju4bPv/7ljp8+Pfg+48erNmoUftDbgw+6c4Vbz8CYOLIAYSIW7SA2oUjzaK8FpOoR6mkG60pKCVENSnvySXfS5ctL0w4fdlUurVq5nkeROumk6AaZ/fznbkBXqIVaAtm71406Pumk0MHIN67h//2/0Oc7/XQ3BYYxVcgChIlILIPYzmro5gy6gz/qIRro06m/iK330WWXucbp8nX4q1e7X9+DBkU2O+imTS5jf/pT5NfOy3M3OnJk5Mfs2ePaClJTVT/4IPz+Awa4cRnB7uH77zVsScSYBAgVIFIwxjN1KuTnl03Lz4fU1MD7d+4MMwbNpZBUnmQCLzebwFieZcyA9dFd+PBhWLgQLrkERMpu694dHn4Y/vMf+Mtfwp9r8WL3fv75kV+/QweYMgVefx0++CD8/nv2wKBBkJ0Nr74KZ58d/phJk2DtWncf5R06BA895D6PHBl5vo1JtGCRo6a9rAQRnXitrKY9eri1fFXdr+AGDVydezQWLnQnnTcv8PbiYjevUcOG4ReOueYat4B9tGsR+NYx6Nw5+DTYqm4iub59XTfcN9+M/PyHDrnG8CFDStP27XMlHd+a08OHR5dnY+KAJK4oNxhYA+QCUwJs7wQsBr4ElgOX+G27yztuDXBRuGtZgIhcLIPYArYn+JaD9F8zYNIkNwvpd99FnqFbb3UP/1BdWr/5xl3rnnuC71NcrNqpk5tvKRaffOLWVAbXhrFiRdntO3a4nlYNGrjG6WhNner+gNnZbjoN34CxCy5Qfe89m5jOJEVSAgSQiltq9DhK16TuUW6fmcBE73MPYL3f52VAQ9ya1mvx1qgO9rIAEbmYBrEF8qc/uZ02bChN85UiJkyIPENdu0bWqDxkiJu6ItiEcrm5Lj+PPx75tcs7fFj1z39Wbd7ctS9MmuRG+W7b5qaLaNgw9nUSNm504zx8f9zhw0un2jYmSUIFiES2QfQDclV1naoeAWYDw8rto8BR3ufmwGbv8zBgtqoeVtXvcCWJfgnMa52ycWPg9F27YOZM17Yg4t5nzoQxY4Kc6M03oXdv6NSpNC09HX7xC3j6adiwIXxmvv3WvS69NPy+kyfD9u3w0kuBty9a5N6jaX8or0EDd53cXLj+evjb36BrVzjjDJfPf/0LBg+O7dwdO8Ldd8O4cbBiBbzxBpx6aux5NSbRgkWOyr6Ay4Gn/L5fDfy13D7tgK+APGA30NdL/yvwM7/9/gFcHuAaE4AcIKdTp06JCa+1UEyD2Mr74QdXXfK731XctnGjK0VEMsjNN0VFJF1Mi4vd1Bg9ewaujrnySreWQDyralascD2omjaN37xNxlQjVONeTKOBZ1U1HbgEeEFEIs6Tqs5U1SxVzWrTpk3CMlkj7NsHzz8P331XJnnWLMjIgJQU9z5rFkyfDo0blz28cWOXHrG33nJxZVj5QiHul/J117lSRLDiis/8+a6n0nHHhb+miPt1/9VXpaUFn+Ji14Pp/PMr9oSqjJNPhgULXPHqvPPid15jaoBEBohNQEe/7+lemr/rgFcAVPW/QBrQOsJjjb/p02HsWPeg7dkTpk7l37/7jOvHF7Nhg3uWb9gAEya43aOqSgrkzTddxDnllMDb77rLvf/hD8HP8eOPrlvpJZdEft1Ro+CYY+CRR8qmr1jhqp8qU70USv36iTmvMdVZsKJFZV9APWAdrpHZ10h9crl93gHGeZ9PwrVBCHAyZRup12GN1MEdPOhamC+6yDWwDhxYsgLPFtrqDG7QpuyLrSopkP37XWPtrbeG3m/iRNcdNNiSk3PnugxFW3Vz333uuK+/Lk37859d2saN0Z3LmDqOZFQxqWohcCOwAFgNvKKqK0VkmogM9Xa7DRgvIsuAl71goaq6EleyWAX8G5ikqkWJymtN9+ktc2DnTs5fcAcZf5nMrF8shm3b+Bkv8iFnM5G/8UtmlOwfrtYnrAUL3OC2QNVL/u66Cxo1cg28vgFs/ubPh2bN4Mwzo7v+xImuMdl/4Nx777nG5I4dgx9njIlOsMhR0151tQTx4ouqn6f005WcpFBcpmuqrzH6U07XL8iMXwni6qvdQve+FcJCWb3azVWUkuLWgfY1IBcXuym9o5newt8117gb3bnT5aNZM9UbbojtXMbUYVTjRmpTSbN/ncOpxZ8zg1/iaufc9BhTp5Y2Rs9mFL1ZSjfWRN8YXV5BgevqOWQI1KsXfv/u3eGzz9wUEnfeCZdf7hrUly2DTZuia3/wN3myu9Enn3RTXuzfn7j2B2PqqAj+DzfV2YgfHudHmvACV5dJ37ixtNH5L3deQfGmyVzffA5tH78nusbo8j76CHbvhssui/yYZs1gzhw4/XS44w7X979/f7ct1gDRs6cLCI89BgcPurSBA2M7lzEmsGBFi5r2qgtVTOWnu3jliR16UNJ0BjeEH9Nwzjmq3btXfozAzTe7xXFiWelN1c182raty2Rl/5v51mJo0sRNgWGMiRpWxVTzzZrluqj6d1ldevPTpOkhnk6bVGbfgNVIo0bB11+7MQSxUoW5c+HCC6FJk9jOcfbZ8MUXrqrptttizwvAxRdDt25w4IBVLxmTABYgaojyU3GnUMR1BU/wWcOzufWp/wk/pmHkSDdv95w5sWdi6VJXdxVN9VIg7du7abJHj67ceVJS4JZb3OcLLqjcuYwxFYgrYdR8WVlZmpOTk+xsJExKivsB73MJ85nPEK5iDnP0yshOctFFbo6h3NzoRxsfOOCizrx58MMPbrBadVBUBP/+d+C1JIwxYYnIElXNCrTNShA1hP98eAC/ZAZbOJYvOkXxa37UKFi3DqINpN9+6xqY582DBx6oPsEBXKno0kstOBiTABYgqqFw8yd1YR0X8w7P1JvAfb9vEPmJhw93U0bMnh35MW++CVlZsHkzvPMO3H57NLdijKnBLEBUM4Eao8vPn/RLnqCYFLr/eUJ0XVaPPtpNVf3KK25yu1CKilzDx2WXuRHKS5a4KipjTJ1hbRDVTEZG4GUUOneG9etxff7T093Moq++Gv0FXnrJtSV89FHwKS527HANyO++69Z2eOwxSEuL/lrGmGrP2iBqkGDzJJWkz57tpp6eNCnwjuEMHermRwpWzbR2LZx2mgsgTz7pXhYcjKmTLEBUM+UboyukL14M7drBOefEdoGmTV2j7quvQmFh2W3LlsGAAbBnD7z/vis9GGPqLAsQ1UzYxXy2bXNVTJXptTNqlDvPBx+Upn38sQs69eq50sPpp8d+fmNMrWABopoZMybMYj5bt0LbtpW7yCWXuJKEr5pp/nw3OrptW/jkE+jRo3LnN8bUCjZZXzU0ZkyI1d22bYM+fSp3gUaN3FoOr7/uJs0bPx4yM1031rq+dKsxpkRCSxAiMlhE1ohIrohMCbD9YRFZ6r2+EZE9ftuK/LbNS2Q+kyXQeIeQVF2AqGwJAlw10+7dcO21bn6k996z4GCMKSNhJQgRSQUeBy4E8oBsEZmnqqt8+6jqZL/9bwJ6+53ioKpmJip/yeYb7+CbX8l/vEPQ0sPu3a5hOR4jmQcNguOPd6WR55+3nkrGmAoSWYLoB+Sq6jpVPQLMBkKtUTkat+xonVB+8j0oXegnqG3b3Hs8AkSDBrBmjRs0Z8HBGBNAIgNEB+B7v+95XloFItIZ6AK855ecJiI5IvJ/IhJwwiERmeDtk7N9+/Z45btKhB3vEIgvQMSjigncPEbGGBNEdenFNAp4TVWL/NI6e6P7fgo8IiLHlz9IVWeqapaqZrWpYfXnYcc7BLJ1q3uvTpPlGWNqrUQGiE1AR7/v6V5aIKMoV72kqpu893XA+5Rtn6jxwo53CCSeVUzGGBNGIgNENtBVRLqISANcEKjQG0lEugMtgP/6pbUQkYbe59bAAGBV+WNrsrDjHQLZutXt3Lp1leXTGFN3JawXk6oWisiNwAIgFXhaVVeKyDTcGqi+YDEKmK1lZw08Cfi7iBTjgtgf/Xs/1RYhxzsEsm2bCw7WdmCMqQIJHSinqm8Db5dLu6fc9/sCHPcp0DOReatKs2a53kkbN7o2hunTowwMPtu2WfWSMabK2EjqBItpvEMw8ZhmwxhjIlRdejHVWjGNdwjGShDGmCpkASLBYhrvEIwFCGNMFbIAkWAxjXcI5NAh2LfPqpiMMVXGAkSCxTTeIRAbA2GMqWIWIBIs5HiHggLo3RveeCP8iSxAGGOqmAWIKjBmDKxfD8XF7r2k99KKFbB0admV3YLxTbNhVUzGmCoSNkCIyE9ExAJJIixZ4t4jabG2EoQxpopF8uC/CvhWRP7kTYth4iUnx71bgDDGVENhA4Sq/gw3Ud5a4FkR+a83zXazhOeutoumBLF1KzRp4l7GGFMFIqo6UtV9wGu4RX/aAcOBL7xV4EwsDh+GZcvcYj07dsCBA6H3tzEQxpgqFkkbxFAR+Sduyu36QD9VvRjoBdyW2OzVHFGvL71ihevFdNFF7vv334feP15rURtjTIQiKUGMBB5W1Z6q+qCqbgNQ1XzguoTmrobwzbe0YQOols63FDJI+KqXRoxw7+GqmbZutRKEMaZKRRIg7gM+930RkUYikgGgqosSkqsaJqb5lnJyoEULOOcc9z1cgLAqJmNMFYskQLwKFPt9L/LSjCem+ZaWLIGsLOjQwdVLbdgQfN/iYti+3aqYjDFVKpIAUU9Vj/i+eJ8bRHJyERksImtEJFdEpgTY/rCILPVe34jIHr9tY0XkW+81NpLrJUvU8y0dOgRffQV9+0K9ei5IhIomu3ZBUZGVIIwxVSqSALFdRIb6vojIMGBHuINEJBV4HLgY6AGMFpEe/vuo6mRVzVTVTOAx4A3v2JbAvcBpQD/gXhFpEdktVb2o51v66ivXQJ2V5b536hQ6QNgYCGNMEkQSIG4AfiMiG0Xke+BO4PoIjusH5KrqOq/UMRsYFmL/0cDL3ueLgIWquktVdwMLgcERXDMpol5f2tdA3beve+/cOXSAsGk2jDFJEHZFOVVdC5wuIk297z9GeO4OgH/fzTxciaACEekMdAHeC3FshwivmxRRrS+dkwOtWrnAAK4E8eqrrq0hJUDMthKEMSYJIlpyVEQuBU4G0kQEAFWdFsd8jAJeU9WiaA4SkQnABIBOUS+wkES+Bmrvb0mnTq7K6YcfoH37ivtbgDDGJEEkA+X+hpuP6SZAgCuAzhGcexPQ0e97upcWyChKq5ciPlZVZ6pqlqpmtWnTJoIsVQMHD7pBcr7qJShtzQ5WzbR1qytZtGqV+PwZY4wnkjaI/qr6c2C3qv4OOAPoFsFx2UBXEekiIg1wQWBe+Z28CQBbAP/1S14ADBKRFl7j9CAvreZbvhwKC0sbqKG0qilYgNi2Ddq0CVz9ZIwxCRJJFdMh7z1fRNoDO3HzMYWkqoUiciPuwZ4KPK2qK0VkGpCjqr5gMQqYrarqd+wuEbkfF2QApqnqrshuqZor30ANpSWIYGMhbJCcMSYJIvlJ+paIHA08CHwBrAdeiuTkqvq2qnZT1eNVdbqXdo9fcEBV71PVCmMkVPVpVT3Bez0TyfWqQtRzLpWXk+NKAx39atCOOgqaNw9dxWQ9mIwxVSxkgPAWClqkqntU9XVc20N3Vb2nSnJXzYSdc+mHH+DFF93GYHJyXOnB10DtE2oshJUgjDFJEDJAqGoxbrCb7/thVd2b8FxVU2HnXHruObj6apg/P/AJ8vNh1aqy7Q8+4QKElSCMMVUskiqmRSIyUqT8T966J+ycS74BbXfe6Rqiy1u2zE2ZEShABBssl58PP/5oJQhjTJWLJEBcj6xYU5cAABwXSURBVJuc77CI7BOR/SKyL8H5qpbCzrm0Y4erOlq1Cp59tuKOgRqo/U+ya5cLBv5sDIQxJkkiWXK0maqmqGoDVT3K+35UVWSuugk759KOHdCnD/TvD/fcU3GVuJwcV1XUIcCg8GBjIWyaDWNMkkQyUO7sQK+qyFx1E3bOpe3bXQ+lBx+ELVvg4YfLniBYAzUEDxBWgjDGJEkk4yBu9/uchpuEbwlwXkJyVM2FnHNpxw7o3t2VIEaMgAcegPHj3a//Awdg9WoYOTLwscEGy1mAMMYkSSRVTD/xe10I/A+wO/FZq4F27HAlCIA//MFNqzHNm7Jq6VI3GV+g9geAdu0gNbXiYDlfFZMFCGNMFYtl7oY84KR4Z6TGO3TINTC3bu2+d+sG118Pf/87rFlT2kAdqAcTuOCQnh64BNGsGTRqlLi8G2NMAGGrmETkMcA38isFyMSNqDb+dnhrKPkCBLiG6uefh9/8Bpo0gWOPDTxbq0+gsRA2SM4YkySRtEHk+H0uBF5W1U8SlJ+aa/t29+4/q2zbtm5MxG9/66bSOOus0Ofo3Bk+/rhsmk2zYYxJkkgCxGvAId9aDSKSKiKNVTU/zHF1S6ASBMDkyTBjhuvVFKx6yadTJ8jLc4PpUlNd2rZtcMIJ8c+vMcaEEdFIasC/ArwR8G5islODBQsQTZqUNlSfFnBBvVKdOrkR2Fu2lKZZFZMxJkkiKUGk+S8zqqo/ikjjUAfUSYGqmHyuu851fx0wIPQ5/MdCpKe7ksSOHVbFZIxJikhKEAdEpI/vi4j0BQ4mLks1lG+ajRYtKm4TgTPPDDxAzl/5sRA7d7qusVaCMMYkQSQB4lbgVRH5SEQ+BuYAN0ZychEZLCJrRCRXRCqs+eDtc6WIrBKRlSLykl96kYgs9V4VVqKrdnbscEuC+toOYuFbI8I3FsIGyRljkihsFZOqZnvLgp7oJa1R1YJwx4lIKm6q8AtxYyeyRWSeqq7y26crcBcwQFV3i4j/k/CgqmZGcS/JtX17xfaHaDVr5kogvhKEzcNkjEmiSOZimgQ0UdUVqroCaCoiv4zg3P2AXFVdp6pHgNnAsHL7jAceV9XdAKq6LbrsJ9iMGbBoUWT77thR+QABZcdCWAnCGJNEkVQxjVfVPb4v3sN8fATHdQC+9/ue56X56wZ0E5FPROT/RGSw37Y0Ecnx0i+L4HrxVVAAt93mgkQkfBP1VVagAGElCGNMEkQSIFL9Fwvyqo4axOn69YCuwEBgNPCkt/41QGdVzQJ+CjwiIseXP1hEJnhBJGe7rxdRvKxY4abP2Lw5sv3jVYLo3Lm0DWLrVqhXD44+OvQxxhiTAJEEiH8Dc0TkfBE5H3gZeCeC4zYBHf2+p3tp/vKAeapaoKrfAd/gAgaqusl7Xwe8D/QufwFVnamqWaqa1SYev979ZWe790gChGp8q5j27nWvbdtcqSQllimzjDGmciJ58twJvAfc4L2+ouzAuWCyga4i0kVEGgCjgPK9kebiSg+ISGtcldM6EWkhIg390gcAq6hKvgCxZYvrahrKnj1uzEK8qpgAvv/eptkwxiRVJNN9FwOfAetxDc/nAasjOK4Q1x12gbf/K6q6UkSmichQb7cFwE4RWQUsBm5X1Z242WJzRGSZl/5H/95PVeLzz917QYEbjxBKsFHUsfAfLGejqI0xSRS0m6uIdMO1C4wGduDGP6Cq50Z6clV9G3i7XNo9fp8V+JX38t/nU6BnpNeJu/x8WLkSTjrJLfKzeXPo0oEvQMSjBOEbLLdhgwsQ3bpV/pzGGBODUCWIr3GlhSGqeqaqPgYUVU22kuzLL12V0TCvV264dghfA3k8ShDHHgv167sAYVVMxpgkChUgRgBbgMUi8qTXQB1mrohawle9FGmAiGcVU0qKm4dp9Wq3Ip1VMRljkiRogFDVuao6CuiOawe4FThGRJ4QkUFVlcGkyM52D+neXsepSEsQ8epJ1akT5HjLcFiAMMYkSSSN1AdU9SVV/Qmuq+qXuJ5NtVd2Npx6KjRs6EoFkZQg0tKgcZwmue3cufSaVsVkjEmSqDrYq+pub+zB+YnKUNLt2gW5uSytfyoZGbBsR3sWPreZWbNCHOMbAxFuttZI+XoygZUgjDFJE8l6EHWLV7Uz9c1+bDgMm2lP64ObuWyC2zxmTIBj4jXNho8FCGNMNWBDdMvzBsh9crgv4AJEO7aQnw9TpwY5Jl6jqH0sQBhjqgELEOV9/jlr6MZe3PxHm2nPsfxACkUlc+hVsGNHfEsQvrEQzZu7dhBjjEkCCxDlZWezskm/kq+baU89imjD9jI/7MuIx1oQ/nwLB1npwRiTRBYg/G3aBFu20GnEqSUdkjbTHoDj0zYzfXqAY44cgX374hsgmjRxq9NZDyZjTBJZgPDnDZDLmngqM2e6mp4tXoCYPmlz4AbqeE6z4e/UU+GUU+J7TmOMiYL1YvKXne3WX8jMZMwZXo+lTe0hHQZ2CzIWIp6jqP3Nnx+/brPGGBMDCxD+srOhZ09o5Debedu27kEdbLBcogKErQFhjEkyewr5FBeXjqD2V6+eCxLBAkS8p9kwxphqwgKET26uW8WtX7+K29q3r/oShDHGJJkFCB/fCnLlSxAQWYBo1Sox+TLGmCRJaIAQkcEiskZEckVkSpB9rhSRVSKyUkRe8ksfKyLfeq+xicwn4HowNWoEPXpU3BYqQGzfDi1auKooY4ypRRL2VBORVOBx4EIgD8gWkXn+S4eKSFfgLmCAqu4WkWO89JbAvUAWoMAS79jdicov2dnQt2/gB3379m51t4ICt5iPv3hPs2GMMdVEIksQ/YBcVV2nqkeA2cCwcvuMBx73PfhVdZuXfhGwUFV3edsWAoMTltOCAreKXKDqJXABQtWt8FZevCfqM8aYaiKRAaID8L3f9zwvzV83oJuIfCIi/ycig6M4FhGZICI5IpKz3debKBYrV8KhQ8EDRLt27j1QNZOVIIwxtVSyG6nrAV2BgcBo4EkROTrSg721KbJUNatNZX7F+5YYDdSDCVwJAixAGGPqlEQGiE1AR7/v6V6avzxgnqoWqOp3wDe4gBHJsfGTnQ0tW8JxxwXeHixAqFoVkzGm1kpkgMgGuopIFxFpAIwC5pXbZy6u9ICItMZVOa0DFgCDRKSFiLQABnlpCcqpN0Au2NQWbdpAamrFALF/v2u/sBKEMaYWSlgvJlUtFJEbcQ/2VOBpVV0pItOAHFWdR2kgWAUUAber6k4AEbkfF2QApqnqroRkND8fVqyAn/wk+D6pqXDssRUDhI2iNsbUYgntvK+qbwNvl0u7x++zAr/yXuWPfRp4OpH5A+DHH+Gaa+CCC0LvF2gshI2iNsbUYja665hj4Mknw+/Xvj2sW1c2zQKEMaYWS3YvppojUAnCqpiMMbWYBYhItW8PO3fC4cOlaVaCMMbUYhYgIuXr6rplS2najh1u6o1mzZKTJ2OMSSALEJEKNBbCNwbCVn4zxtRCFiAiFShA2ChqY0wtZgEiUqFKEMYYUwtZgIhUq1auvcFKEMaYOsICRKREKnZ1tQBhjKnFLEBEwz9AFBTA7t1WxWSMqbUsQETDP0Ds8qaGshKEMaaWsgARDf8AYYPkjDG1nAWIaLRvD3v3woEDNs2GMabWswARDf/R1FaCMMbUchYgouE/FsJKEMaYWi6hAUJEBovIGhHJFZEpAbaPE5HtIrLUe/3Cb1uRX3r5leiSwz9A+EoQrVolLz/GGJNACVsPQkRSgceBC3FrT2eLyDxVXVVu1zmqemOAUxxU1cxE5S8m5QPEUUdBgwbJzZMxxiRIIksQ/YBcVV2nqkeA2cCwBF4v8Zo3h0aNSquYrHrJGFOLJTJAdAC+9/ue56WVN1JElovIayLS0S89TURyROT/ROSyQBcQkQnePjnbfW0CieQ/mtpGURtjarlkN1K/BWSo6inAQuA5v22dVTUL+CnwiIgcX/5gVZ2pqlmqmtWmqn7Nt2tX2ovJAoQxphZLZIDYBPiXCNK9tBKqulNVfUu0PQX09du2yXtfB7wP9E5gXiPnK0FYFZMxppZLZIDIBrqKSBcRaQCMAsr0RhKRdn5fhwKrvfQWItLQ+9waGACUb9xOjvbtYdMmK0EYY2q9hPViUtVCEbkRWACkAk+r6koRmQbkqOo84GYRGQoUAruAcd7hJwF/F5FiXBD7Y4DeT8nRvr0bSQ0WIIwxtVrCAgSAqr4NvF0u7R6/z3cBdwU47lOgZyLzFjNfV1ewKiZjTK2W7Ebqmsc/QFgJwhhTi1mAiJaVIIwxdURCq5hqJStBGFNBQUEBeXl5HDp0KNlZMUGkpaWRnp5O/fr1Iz7GAkS0mjWDpk3hxx8tQBjjycvLo1mzZmRkZCAiyc6OKUdV2blzJ3l5eXTp0iXi46yKKRbt20NqKhx9dLJzYky1cOjQIVq1amXBoZoSEVq1ahV1Cc9KELHwLRxk/zMYU8KCQ/UWy38fK0HEYsAAOOOMZOfCGOPZuXMnmZmZZGZmcuyxx9KhQ4eS70eOHAl5bE5ODjfffHPYa/Tv3z9e2a0xRFWTnYe4yMrK0pycnGRnw5g6afXq1Zx00kkR7z9rFkydChs3QqdOMH06jBkTn7zcd999NG3alF//+tclaYWFhdSrZxUmgf47icgSb967CqwEYYypUrNmwYQJsGEDqLr3CRNcejyNGzeOG264gdNOO4077riDzz//nDPOOIPevXvTv39/1qxZA8D777/PkCFDABdcrr32WgYOHMhxxx3Ho48+WnK+pk2bluw/cOBALr/8crp3786YMWPw/dB+++236d69O3379uXmm28uOa+/9evXc9ZZZ9GnTx/69OnDp59+WrLtgQceoGfPnvTq1YspU9waa7m5uVxwwQX06tWLPn36sHbt2vj+oUKwkGqMqVJTp0J+ftm0/HyXHq9ShE9eXh6ffvopqamp7Nu3j48++oh69erx7rvv8pvf/IbXX3+9wjFff/01ixcvZv/+/Zx44olMnDixQtfQL7/8kpUrV9K+fXsGDBjAJ598QlZWFtdffz0ffvghXbp0YfTo0QHzdMwxx7Bw4ULS0tL49ttvGT16NDk5Obzzzju8+eabfPbZZzRu3Jhdu3YBMGbMGKZMmcLw4cM5dOgQxcXF8f0jhWABwhhTpTZujC69Mq644gpSU1MB2Lt3L2PHjuXbb79FRCgoKAh4zKWXXkrDhg1p2LAhxxxzDFu3biU9Pb3MPv369StJy8zMZP369TRt2pTjjjuupBvp6NGjmTlzZoXzFxQUcOONN7J06VJSU1P55ptvAHj33Xe55ppraNy4MQAtW7Zk//79bNq0ieHDhwNuLENVsiomY0yV6tQpuvTKaNKkScnn3/72t5x77rmsWLGCt956K2iXz4YNG5Z8Tk1NpbCwMKZ9gnn44Ydp27Yty5YtIycnJ2wjejJZgDDGVKnp08H7kVyicWOXnkh79+6lQwe3qOWzzz4b9/OfeOKJrFu3jvXr1wMwZ86coPlo164dKSkpvPDCCxQVFQFw4YUX8swzz5Dv1b/t2rWLZs2akZ6ezty5cwE4fPhwyfaqYAHCGFOlxoyBmTOhc2c3lKhzZ/c93u0P5d1xxx3cdddd9O7dO6pf/JFq1KgRM2bMYPDgwfTt25dmzZrRvHnzCvv98pe/5LnnnqNXr158/fXXJaWcwYMHM3ToULKyssjMzOShhx4C4IUXXuDRRx/llFNOoX///vzwww9xz3sw1s3VGFNp0XZzra1+/PFHmjZtiqoyadIkunbtyuTJk5OdrRLVqpuriAwWkTUikisiUwJsHyci20Vkqff6hd+2sSLyrfcam8h8GmNMPDz55JNkZmZy8skns3fvXq6//vpkZ6lSEtaLSURSgceBC4E8IFtE5gVYGW6Oqt5Y7tiWwL1AFqDAEu/Y3YnKrzHGVNbkyZOrVYmhshJZgugH5KrqOlU9AswGhkV47EXAQlXd5QWFhcDgBOXTGGNMAIkMEB2A7/2+53lp5Y0UkeUi8pqIdIzyWGOMMQmS7F5MbwEZqnoKrpTwXDQHi8gEEckRkZzt27cnJIPGGFNXJTJAbAI6+n1P99JKqOpOVT3sfX0K6Bvpsd7xM1U1S1Wz2tjyn8YYE1eJDBDZQFcR6SIiDYBRwDz/HUSknd/XocBq7/MCYJCItBCRFsAgL80YYyo499xzWbCg7CPikUceYeLEiUGPGThwIL6u8Zdccgl79uypsM99991XMh4hmLlz57JqVWnfm3vuuYd33303muxXWwkLEKpaCNyIe7CvBl5R1ZUiMk1Ehnq73SwiK0VkGXAzMM47dhdwPy7IZAPTvDRjjKlg9OjRzJ49u0za7Nmzg06YV97bb7/N0TGuEFk+QEybNo0LLrggpnNVNwltg1DVt1W1m6oer6rTvbR7VHWe9/kuVT1ZVXup6rmq+rXfsU+r6gne65lE5tMYU7NdfvnlzJ8/v2Reo/Xr17N582bOOussJk6cSFZWFieffDL33ntvwOMzMjLYsWMHANOnT6dbt26ceeaZJVOCgxvjcOqpp9KrVy9GjhxJfn4+n376KfPmzeP2228nMzOTtWvXMm7cOF577TUAFi1aRO/evenZsyfXXnsthw8fLrnevffeS58+fejZsydff/11hTxVh2nBbTZXY0x83XorLF0a33NmZsIjjwTd3LJlS/r168c777zDsGHDmD17NldeeSUiwvTp02nZsiVFRUWcf/75LF++nFNOOSXgeZYsWcLs2bNZunQphYWF9OnTh759XdPoiBEjGD9+PAB33303//jHP7jpppsYOnQoQ4YM4fLLLy9zrkOHDjFu3DgWLVpEt27d+PnPf84TTzzBrbfeCkDr1q354osvmDFjBg899BBPPfVUmeOrw7Tgye7FZIwxceFfzeRfvfTKK6/Qp08fevfuzcqVK8tUB5X30UcfMXz4cBo3bsxRRx3F0KFDS7atWLGCs846i549ezJr1ixWrlwZMj9r1qyhS5cudOvWDYCxY8fy4YcflmwfMWIEAH379i2Z4M9fQUEB48ePp2fPnlxxxRUl+Y50WvDG5WdEjIGVIIwx8RXil34iDRs2jMmTJ/PFF1+Qn59P3759+e6773jooYfIzs6mRYsWjBs3Lug03+GMGzeOuXPn0qtXL5599lnef//9SuXXN2V4sOnC/acFLy4urvK1IMBKEMyaBRkZkJLi3uO97KExpmo0bdqUc889l2uvvbak9LBv3z6aNGlC8+bN2bp1K++8807Ic5x99tnMnTuXgwcPsn//ft56662Sbfv376ddu3YUFBQwy+9B0axZM/bv31/hXCeeeCLr168nNzcXcLOynnPOORHfT3WYFrxOB4iqWhvXGFM1Ro8ezbJly0oCRK9evejduzfdu3fnpz/9KQMGDAh5fJ8+fbjqqqvo1asXF198MaeeemrJtvvvv5/TTjuNAQMG0L1795L0UaNG8eCDD9K7d+8yDcNpaWk888wzXHHFFfTs2ZOUlBRuuOGGiO+lOkwLXqen+87IcEGhvM6dIUCVoDEmCJvuu2aoVtN9V3dVuTauMcbUNHU6QFTl2rjGGFPT1OkAkay1cY0xpiao0wEiWWvjGlMb1Zb2zNoqlv8+dX4cxJgxFhCMqay0tDR27txJq1atEJFkZ8eUo6rs3Lkz6rEUdT5AGGMqLz09nby8PGxdluorLS2N9PT0qI6xAGGMqbT69evTpUuXZGfDxFmdboMwxhgTnAUIY4wxAVmAMMYYE1CtmWpDRLYDASbOiFhrYEecslOT2H3XLXbfdUsk991ZVdsE2lBrAkRliUhOsPlIajO777rF7rtuqex9WxWTMcaYgCxAGGOMCcgCRKmZyc5Akth91y1233VLpe7b2iCMMcYEZCUIY4wxAdX5ACEig0VkjYjkisiUZOcnkUTkaRHZJiIr/NJaishCEfnWe2+RzDzGm4h0FJHFIrJKRFaKyC1eem2/7zQR+VxElnn3/TsvvYuIfOb9e58jIg2SnddEEJFUEflSRP7lfa8r971eRL4SkaUikuOlxfxvvU4HCBFJBR4HLgZ6AKNFpEdyc5VQzwKDy6VNARapaldgkfe9NikEblPVHsDpwCTvv3Ftv+/DwHmq2gvIBAaLyOnAA8DDqnoCsBu4Lol5TKRbgNV+3+vKfQOcq6qZft1bY/63XqcDBNAPyFXVdap6BJgNDEtynhJGVT8EdpVLHgY8531+DrisSjOVYKq6RVW/8D7vxz00OlD771tV9Ufva33vpcB5wGteeq27bwARSQcuBZ7yvgt14L5DiPnfel0PEB2A7/2+53lpdUlbVd3iff4BaJvMzCSSiGQAvYHPqAP37VWzLAW2AQuBtcAeVS30dqmt/94fAe4Air3vragb9w3uR8B/RGSJiEzw0mL+t27TfZsSqqoiUiu7tYlIU+B14FZV3ee/qE1tvW9VLQIyReRo4J9A9yRnKeFEZAiwTVWXiMjAZOcnCc5U1U0icgywUES+9t8Y7b/1ul6C2AR09Pue7qXVJVtFpB2A974tyfmJOxGpjwsOs1T1DS+51t+3j6ruARYDZwBHi4jvh2Ft/Pc+ABgqIutxVcbnAX+h9t83AKq6yXvfhvtR0I9K/Fuv6wEiG+jq9XBoAIwC5iU5T1VtHjDW+zwWeDOJeYk7r/75H8BqVf2z36baft9tvJIDItIIuBDX/rIYuNzbrdbdt6reparpqpqB+//5PVUdQy2/bwARaSIizXyfgUHACirxb73OD5QTkUtwdZapwNOqOj3JWUoYEXkZGIib4XErcC8wF3gF6ISbDfdKVS3fkF1jiciZwEfAV5TWSf8G1w5Rm+/7FFyDZCruh+ArqjpNRI7D/bJuCXwJ/ExVDycvp4njVTH9WlWH1IX79u7xn97XesBLqjpdRFoR47/1Oh8gjDHGBFbXq5iMMcYEYQHCGGNMQBYgjDHGBGQBwhhjTEAWIIwxxgRkAcKYMESkyJsd0/eK28R+IpLhP7uuMdWJTbVhTHgHVTUz2ZkwpqpZCcKYGHlz7//Jm3//cxE5wUvPEJH3RGS5iCwSkU5eelsR+ae3RsMyEenvnSpVRJ701m34jzfyGRG52VvHYrmIzE7SbZo6zAKEMeE1KlfFdJXftr2q2hP4K25EPsBjwHOqegowC3jUS38U+MBbo6EPsNJL7wo8rqonA3uAkV76FKC3d54bEnVzxgRjI6mNCUNEflTVpgHS1+MW5VnnTQj4g6q2EpEdQDtVLfDSt6hqaxHZDqT7T/HgTUG+0FvMBRG5E6ivqv8rIv8GfsRNhzLXb30HY6qElSCMqRwN8jka/nMCFVHaNngpbsXDPkC232ykxlQJCxDGVM5Vfu//9T5/iptJFGAMbrJAcMs9ToSSxXyaBzupiKQAHVV1MXAn0ByoUIoxJpHsF4kx4TXyVmbz+beq+rq6thCR5bhSwGgv7SbgGRG5HdgOXOOl3wLMFJHrcCWFicAWAksFXvSCiACPeus6GFNlrA3CmBh5bRBZqroj2XkxJhGsiskYY0xAVoIwxhgTkJUgjDHGBGQBwhhjTEAWIIwxxgRkAcIYY0xAFiCMMcYEZAHCGGNMQP8fEHoPIb83dmEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GUNnnH3Tvnvl"
   },
   "source": [
    "## 3. Train (again) and evaluate the model\n",
    "\n",
    "- To this end, you have found the \"best\" hyper-parameters. \n",
    "- Now, fix the hyper-parameters and train the network on the entire training set (all the 50K training samples)\n",
    "- Evaluate your model on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOKWUPX7vnvl"
   },
   "source": [
    "### 3.1. Train the model on the entire training set\n",
    "\n",
    "Why? Previously, you used 40K samples for training; you wasted 10K samples for the sake of hyper-parameter tuning. Now you already know the hyper-parameters, so why not using all the 50K samples for training?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "bqzmGV62vnvm"
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rotation_range=15,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    shear_range=0.3,\n",
    "    zoom_range=0.1,\n",
    "    horizontal_flip=True)\n",
    "\n",
    "train_datagen.fit(x_tr)\n",
    "train_generator = train_datagen.flow(x_train, y_train_vec, batch_size=64)\n",
    "\n",
    "learning_rate = 0.001 # to be tuned!\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=learning_rate),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NK3fIh6gvnvm",
    "outputId": "917bd5ff-b260-461f-bbde-4564e9c7a355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "782/782 [==============================] - 30s 37ms/step - loss: 1.6912 - acc: 0.4086\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 1.0118 - acc: 0.6358\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.8713 - acc: 0.6932\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.7868 - acc: 0.7267\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.7217 - acc: 0.7496\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 30s 38ms/step - loss: 0.6723 - acc: 0.7678\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.6445 - acc: 0.7784\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.6189 - acc: 0.7898\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5981 - acc: 0.7959\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5708 - acc: 0.8049\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5573 - acc: 0.8106\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5373 - acc: 0.8171\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5174 - acc: 0.8232\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.5093 - acc: 0.8262\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4972 - acc: 0.8326\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 29s 38ms/step - loss: 0.4871 - acc: 0.8356\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4779 - acc: 0.8389\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4688 - acc: 0.8413\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4581 - acc: 0.8441\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 29s 36ms/step - loss: 0.4540 - acc: 0.8494\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 29s 36ms/step - loss: 0.4429 - acc: 0.8524\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 29s 36ms/step - loss: 0.4318 - acc: 0.8541\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.4295 - acc: 0.8559\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4128 - acc: 0.8601\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 29s 36ms/step - loss: 0.4147 - acc: 0.8597\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4111 - acc: 0.8606\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.4072 - acc: 0.8607\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3903 - acc: 0.8690\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3953 - acc: 0.8639\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 29s 36ms/step - loss: 0.3913 - acc: 0.8670\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3784 - acc: 0.8712\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3745 - acc: 0.8739\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3832 - acc: 0.8697\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3666 - acc: 0.8737\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3689 - acc: 0.8745\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 29s 36ms/step - loss: 0.3631 - acc: 0.8806\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 28s 36ms/step - loss: 0.3553 - acc: 0.8790\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3496 - acc: 0.8824\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3449 - acc: 0.8822\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3507 - acc: 0.8821\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3485 - acc: 0.8820\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3459 - acc: 0.8833\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3391 - acc: 0.8852\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3365 - acc: 0.8868\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3357 - acc: 0.8872\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3262 - acc: 0.8893\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3308 - acc: 0.8872\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3311 - acc: 0.8899\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3217 - acc: 0.8932\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 29s 37ms/step - loss: 0.3270 - acc: 0.8896\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_generator, epochs=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SjgbZFtXvnvm"
   },
   "source": [
    "### 3.2. Evaluate the model on the test set\n",
    "\n",
    "Do NOT used the test set until now. Make sure that your model parameters and hyper-parameters are independent of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Il0VuyAvnvm",
    "outputId": "5cdaad17-b43b-479b-c1fd-d3a2ee6cab0c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.4155 - acc: 0.8736\n",
      "loss = 0.41546380519866943\n",
      "accuracy = 0.8736000061035156\n"
     ]
    }
   ],
   "source": [
    "loss_and_acc = model.evaluate(x_test, y_test_vec)\n",
    "print('loss = ' + str(loss_and_acc[0]))\n",
    "print('accuracy = ' + str(loss_and_acc[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "27sPxW53vnvm"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "HM4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
